<!DOCTYPE html>
<html>
  <head>
    <!-- head section -->
    <meta charset="utf-8" />
    <title>Renata Sidorenko</title>
    <meta name="viewport" content="width=device-width" />
    <link rel="stylesheet" href="https://use.typekit.net/wfc0dpl.css" />
    <link rel="stylesheet" href="https://use.typekit.net/xjp6kcj.css" />
    <link href="index.css" rel="stylesheet" />
  </head>

  <body>
    <canvas id="gradient-canvas" data-transition-in></canvas>

    <!--Gradient for header-->
    <div class="bg-left"></div>
    <section class="bg-container">
      <div class="bg-left"></div>
    </section>

    <!--Header-->
    <a href="index.html"><div id="header-title">RENATA SIDORENKO</div></a>
    <div id="toggle">
      <div class="icon">
        <span></span>
        <span></span>
        <span></span>
      </div>
    </div>

    <div id="toggle2">
      <div class="icon2">
        <span></span>
        <span></span>
        <span></span>
      </div>
    </div>

    <div class="page-header">
      <nav id="navMenu">
        <ul class="menu" id="menu">
          <li><a class="navLink" href="#abstract">Abstract</a></li>
          <li>
            <a class="navLink" href="#chapterI">The concept of archetypes</a>
          </li>
          <li>
            <a class="navLink" href="#chapterII"
              >Archetypes, symbols, myths and dreams</a
            >
          </li>
          <li>
            <a class="navLink" href="#chapterIII">The Lover archetype in art</a>
          </li>
          <li><a class="navLink" href="#chapterIV">Advertisemen</a></li>
          <li>
            <a class="navLink" href="#chapterV"
              >The journey of visual exploration</a
            >
          </li>
          <li><a class="navLink" href="#conclusions">Conclusions</a></li>
        </ul>
      </nav>
    </div>

    <div class="hero">
      <h1>
        The Allure of the Lover <br />
        Archetype.
      </h1>
      <h3>
        An Exploration of its Use and Meaning in Advertising, Art, and AI.
      </h3>
    </div>

    <div class="flex-container">
      <!-- THESIS -->

      <div class="abstract">
        <a id="abstract" class="chapter-title">Abstract</a>
      </div>

      <div class="abstract-body">
        This thesis explores the application of archetypes in advertising and
        visual art by drawing upon the work of Carl Jung “The Archetypes and the
        Collective Unconscious” and Margaret Mark and Carol S. Pearson's book
        "The Hero and the Outlaw". The research involves both theoretical and
        practical components, including an assessment of artworks by Gustav
        Klimt, Yayoi Kusama, Tracey Emin, Anna Ridler, and Daria Jelonek, as
        well as examining iconic Chanel advertisements and generated images
        using Midjourney's AI technology.<br /><br />

        My fascination with psychology and belief in the fundamental role of
        archetypes in producing impactful designs motivated me to choose this
        research topic. Given the scope of the topic, I decided to focus on
        exploring the Lover archetype in-depth, which is a personal favorite
        that I recognized as relevant to my own work.<br /><br />

        My thesis argues that although the representation of the Lover archetype
        in visual art has evolved away from conventional romanticized
        stereotypes, advertising has yet to catch up. As a result, one of the
        findings of this study is that designers must be cautious and thoughtful
        about the tools and information they employ in their work.<br /><br />

        The study concludes that based on the research findings, the Lover
        archetype should be depicted in advertising in a more varied and
        contemporary style. Ultimately, the thesis emphasizes the importance of
        archetypes and recommends a more nuanced and critical approach to their
        use in practice.
      </div>

      <div class="chapterI">
        <a id="chapterI" class="chapter-title"
          ><h2>The concept of archetypes</h2></a
        >
        <p>
          Jungian psychology is a theory of the human psyche developed by Carl
          Jung. It proposes that the human psyche is comprised of three parts:
          the conscious, the personal unconscious, and the collective
          unconscious. The collective unconscious, according to Jung, is a deep
          layer of the psyche that is shared by all humans and is made up of
          archetypes.
        </p>
        <p>
          Archetypes are universal symbols or images that have a deep and
          profound meaning for humans. They are inherited from our ancestors and
          are part of our collective unconscious. Archetypes are patterns of
          behavior, thought, and emotion that are repeated throughout history
          and across cultures. They link the conscious mind with subconscious
          meanings, concepts, and desires, that Joseph Campbell says are
          “inherently expressive ... of common human needs, instincts, and
          potentials.”
          <sup class="footnote-ref" id="fnref:1"
            ><a rel="footnote" href="#fn:1">1</a></sup
          >
        </p>
      </div>

      <div class="chapterII">
        <a id="chapterII" class="chapter-title"
          ><h2>Archetypes, symbols, myths <br />and dreams</h2></a
        >

        <p>
          Archetypes, symbols, myths and dreams are closely related concepts in
          Jungian psychology, as they are all ways of understanding and
          expressing the universal patterns and themes that exist in the human
          psyche. C. Jung wrote, "The archetype is an irrepresentable aspect of
          the psyche, or an aspect that can only be represented in a fragmented,
          distorted or symbolic form."

          <sup class="footnote-ref" id="fnref:2"
            ><a rel="footnote" href="#fn:2">2</a></sup
          >
        </p>

        <p>
          Joseph Campbell expanded on Jung's work by studying the myths and
          stories of cultures around the world. He believed that myths are the
          stories that we tell to make sense of the world and to find meaning in
          our lives.For Campbell, myths are like "public dreams," and the
          symbols in myths reflect the archetypal patterns of the human
          psyche.He wrote, "The symbols of mythology are not manufactured; they
          cannot be ordered, invented, or permanently suppressed. They are
          spontaneous productions of the psyche, and each bear within it,
          undamaged, the germ power of its source."
          <sup class="footnote-ref" id="fnref:3"
            ><a rel="footnote" href="#fn:3">3</a></sup
          >
        </p>

        <p>
          The connection between archetypes, symbols, and myths is essential to
          understand the human experience. Archetypes represent basic human
          experiences and patterns of behavior, which are expressed through
          symbols in myths,dreams, and art. Myths give shape and meaning to the
          world, and provide a framework for understanding the mysteries of the
          universe. Symbols in dreams and other forms of expression are the way
          that the unconscious communicates with the conscious mind,
          representing repressed desires and conflicts.
          <sup class="footnote-ref" id="fnref:4"
            ><a rel="footnote" href="#fn:4">4</a></sup
          >
        </p>
      </div>

      <div class="chapterIII">
        <a id="chapterIII" class="chapter-title"
          ><h2>
            The Lover Archetype<br />
            in Art - From Romanticizing to Complete Truthfulness
          </h2></a
        >

        <p>
          In paintings from earlier times, the representation of the lover
          archetype was often idealized and romanticized, being full of passion,
          sensuality, and beauty. These paintings aimed to capture the essence
          of love and desire in a way that was both enchanting and uplifting,
          representing a form of escapism from the harsh realities of everyday
          life.
        </p>

        <p>
          An example of a painting that romanticizes the lover archetype is "The
          Kiss" (1) by Gustav Klimt. This painting, which was completed in 1908,
          depicts a couple in a romantic embrace, with the woman's face turned
          towards the viewer and the man's face obscured.
        </p>

        <p>
          “The Kiss” is a celebration of physical intimacy and romantic passion.
          Through the use of rich colors, patterns, and symbols, Klimt elevates
          the act of romantic intimacy to a sacred and transcendent level. The
          painting celebrates the power of love to bring harmony and balance to
          the world and suggests that it is a force that is capable of
          transcending the boundaries of humanity.
        </p>

        <div class="image-2">
          <img src="images/figure1.png" width="100%" height="auto" />
          <div class="image-footnotes">
            Figure 1: The Kiss by Gustav Klimt, 1908-1909
          </div>
        </div>

        <p>
          Contemporary art has continued to explore the theme of love, but with
          an expanded range of representation that includes a variety of forms
          and types of love. Artists have conveyed a wider spectrum of love
          topics including romantic love, platonic love, familial love,
          self-love, and societal love, including love with darker and more
          complicated aspects.
        </p>
        <p>
          One example of contemporary art that explores love is Yayoi Kusama's
          Infinity Mirrored Room—"Love Forever" installation. This installation
          is a version of Kusama's second mirrored environment, which combines
          sculpture, architecture, and performance art. It blurs the boundaries
          between different artistic disciplines and relies on audience
          participation to come to life. The hexagonal-shaped installation is
          mirrored on all sides and has two peepholes that allow visitors to
          look in and see themselves and another participant repeated
          infinitely. Kusama created this work while experimenting with new
          technology, and she saw it as a "machine for animation." When Kusama
          first exhibited the installation, she distributed buttons with the
          message "Love Forever" printed on them. For the artist, this concept
          represented civil rights, sexual liberation, the anti-war movement,
          and the activism of the 1960s. (Figure 2)
        </p>

        <div class="image-2">
          <img src="images/figure2.png" width="100%" height="auto" />
          <div class="image-footnotes">
            Figure 2: Infinity Mirrored Room — Love Forever by Yayoi Kusama,
            1966/1994
          </div>
        </div>

        <p>
          A totally different representation of love is given by Tracey Emin in
          "My Bed" installation. Through her work, Emin presents a deeply
          personal and intimate portrayal of a specific kind of love - one that
          is fraught with pain and vulnerability. In her installation, Emin is
          able to convey the complexity of love and relationships, showing the
          pain and vulnerability that can come with emotional intimacy. The bed,
          which is the central focus of the installation, is both a physical
          representation of intimacy and a symbol of isolation. The viewer is
          invited to confront the intimate details of Emin's personal life,
          including the mess and chaos that can come with emotional turmoil.
        </p>

        <p>
          The installation is a powerful exploration of a specific kind of love
          - one that is complicated and often painful. Through the discarded
          objects that litter the bed, Emin shows the rawness of emotional
          vulnerability and the devastation that can come with the end of a
          relationship. The empty alcohol bottles and discarded underwear convey
          a sense of desperation and loneliness, highlighting the emotional toll
          that love can take on an individual.(Figure 3)
        </p>

        <div class="image-3">
          <img src="images/figure3.png" width="100%" height="auto" />
          <div class="image-footnotes">
            Figure 3: My Bed by Tracey Emin, 1999-2000
          </div>
        </div>

        <p>
          Overall, the shift in representation of the lover archetype in art
          from older centuries to contemporary art reflects changing cultural
          attitudes towards love and relationships. Contemporary artists are
          more willing to explore the darker, more complicated aspects of love,
          rather than simply romanticizing it as was often done in the past. By
          exploring these themes in their work, contemporary artists are able to
          present a more honest and complex portrayal of love, reflecting the
          realities of human relationships in the 21st century.
        </p>
      </div>

      <div class="chapterIV">
        <a id="chapterIV" class="chapter-title"
          ><h2>Advertisement - the Translation of the Lover Archetype</h2></a
        >

        <p>
          Nowadays most advertising agencies use archetypes in their practice.
          The effectiveness of such advertising is ensured by the unconditional
          demand for images associated with the symbolism of universal values,
          roles, and motives. The most important element of the advertising
          "message" is not so much the visual image as its connotative meaning,
          which can cause an emotional connection, activate the necessary
          associative reactions and encourage purchase of goods.
        </p>

        <p>
          Based on the psychological archetypes of Carl Jung, renowned marketers
          Margaret Mark and Carol Pearson wrote “The Hero and the Outlaw”, a
          book about the use of archetypes in brand building and promotional
          merchandise. As a basis, they took 12 archetypes (the Innocent, the
          Explorer, the Sage, the Caregiver, the Creator, the Ruler, the Hero,
          the Outlaw, the Magician, the Regular Guy, the Lover, and the Jester)
          described by C. Jung and draw a parallel between them and the needs
          according to A. Maslow's pyramid.(Figure 4)
        </p>

        <div class="image-4">
          <img src="images/figure4.png" width="70%" height="auto" />
          <div class="image-footnotes">
            Figure 4: Table from the book <i>The Hero and the Outlaw</i> by
            Atak, 2013
          </div>
        </div>
        <br />
        <p>
          As you can see from figure 4, Mark and Pearson decomposed the
          archetypal image into separate elements, following which it became
          possible to encode the archetypal image into an advertising message.
          Their book became a popular tool that marketers and graphic designers
          use to create brands and advertising campaigns that resonate with
          consumers.
        </p>

        <p>
          One of the archetypes that has been successfully used in branding is
          the Lover archetype. According to Mark and Pearson, the Lover
          archetype represents the desire for intimacy, connection, and
          sensuality. This archetype is often used in the fashion and beauty
          industries to create brands that evoke desire and passion.
        </p>

        <p>
          For example, the Chanel brand is considered to be a good example of
          how the Lover archetype can be used to create a successful brand
          strategy. Chanel's founder, Gabrielle "Coco" Chanel, was known for her
          iconic designs that challenged the conventions of women's fashion. Her
          designs were sensual, luxurious, and romantic, all of which align with
          the Lover archetype.(5) As the brand has evolved, it has continued to
          use this archetype to create campaigns that tap into consumers'
          desires for beauty, romance, and sensuality. “From the elegant
          packaging of their products to the sophisticated visual imagery of
          their advertising campaigns, Chanel is able to evoke the emotions and
          associations that are connected with the lover archetype.” – according
          to Mark and Pearson.
        </p>
        <p></p>

        <div class="image-5">
          <img src="images/figure5.png" width="100%" height="auto" />
          <div class="image-footnotes">
            Figure 5: Advertisement of CHANEL No. 5, 1957 and 2005
          </div>
        </div>

        <p>
          For example, the Chanel brand is considered to be a good example of
          how the Lover archetype can be used to create a successful brand
          strategy. Chanel's founder, Gabrielle "Coco" Chanel, was known for her
          iconic designs that challenged the conventions of women's fashion. Her
          designs were sensual, luxurious, and romantic, all of which align with
          the Lover archetype.(Figure 5) As the brand has evolved, it has
          continued to use this archetype to create campaigns that tap into
          consumers' desires for beauty, romance, and sensuality. “From the
          elegant packaging of their products to the sophisticated visual
          imagery of their advertising campaigns, Chanel is able to evoke the
          emotions and associations that are connected with the lover
          archetype.” – according to Mark and Pearson.
          <sup class="footnote-ref" id="fnref:5"
            ><a rel="footnote" href="#fn:5">5</a></sup
          >
        </p>

        <p>
          However, while Chanel may be successful in their use of the lover
          archetype, it is important to note that the forms of representation
          used in many Chanel advertising are still stereotyped.(Figure 6) These
          representations often depict idealized versions of the lover archetype
          that are unattainable for most people, and which perpetuate narrow and
          limited ideals of beauty and desirability.
        </p>

        <div class="image-2">
          <img src="images/figure6.png" width="100%" height="auto" />
          <div class="image-footnotes">
            Figure 6: Keira Knightley, promoting the Chanel perfume.
          </div>
        </div>

        <p>
          Contemporary artists are increasingly challenging these narrow and
          limiting representations, instead seeking to represent the lover
          archetype in more honest and real ways that reflect the diversity and
          imperfections of real people. This shift reflects a broader change in
          society towards greater acceptance and celebration of diversity, and a
          rejection of narrow and limiting ideals of beauty and desirability.
        </p>
        <br /><br />
        <h4>
          Then how is it possible that advertisings like Chanel can still
          achieve good purchase results when they are based on outdated and
          stereotyped representations of archetypes?
        </h4>
        <br /><br />

        <p>
          One answer may lie in the fact that these representations are deeply
          ingrained in our culture and are reinforced by many different forms of
          media. People may continue to respond to these representations simply
          because they are familiar and because they tap into deeply ingrained
          beliefs and associations.
        </p>
        <p>
          This timeless topic of the role of women and men in ancient societies
          is revisited by John Berger revisits in his "Ways of Seeing." He
          observes that men have historically held more power than women, who
          have been regarded as weaker. Rather than address sexism directly,
          Berger takes a fresh approach. He explains that in the past, a man's
          presence conveyed the message that he could do something for or to
          you. On the other hand, women were not typically viewed as active
          agents; rather, they were passive subjects of male action. Berger
          explains in a unique way that; in the past, a man’s presence is one
          that "suggests that he is capable of doing to you or for you" . While
          women do not “do”, instead they are dealt with. A woman's power,
          according to Berger, was derived from how men perceived her.(Figure 7)
        </p>

        <div class="image-5">
          <img src="images/figure7.png" width="100%" height="auto" />
          <div class="image-footnotes">
            Figure 7: Reclining Bacchante by Trutat,1824-1848, from “Ways of
            Seeing”, John Berger
          </div>
        </div>

        <p>
          However, as society continues to change and evolve, it is likely that
          the forms of representation associated with the Lover archetype will
          also continue to evolve. As new forms of media and communication
          emerge, and as people become more aware of the limitations of narrow
          and stereotyped representations, it is possible that we will see a
          shift towards more honest and real representations of the lover
          archetype. A good example of this change is the case of Victoria
          Secret.
        </p>

        <p>
          For years, the brand relied on the Lover archetype to create
          advertising campaigns that objectified and sexualized women. As you
          can see in Figure 8, the marketers of the brand relied too heavily on
          the outdated stereotyped lover archetype and overlooked the
          individuality of their target audience. This approach led to criticism
          that the brand was perpetuating unrealistic beauty standards and
          promoting a narrow definition of femininity. In recent years, the
          brand has shifted its strategy which is shown in Figure 9 to focus on
          inclusivity and diversity, but the damage has already been done to
          some extent.
        </p>

        <div class="image-3">
          <img src="images/figure8.png" width="80%" height="auto" />
          <div class="image-footnotes">
            Figure 8: Models Elsa Hosk, Lily Aldridge, Alessandra Ambrosio,
            Adriana Lima and Candice Swanepoel <br />at Victoria's Secret
            Fashion Show, 2017
          </div>
        </div>

        <div class="image-9">
          <img src="images/figure9.png" width="90%" height="auto" />
          <div class="image-footnotes">
            Figure 9: The new Victoria’s Secret ad campaign, 2022
          </div>
        </div>
      </div>

      <div class="chapterV">
        <a id="chapterV" class="chapter-title"
          ><h2>Midjourney - The Journey of Visual Exploration</h2></a
        >

        <p>
          When I was starting my research, it was clear to me how the archetypes
          are used by marketing and creative agencies, but I was wondering if
          there was a way for me to use them as a tool for creating art that was
          meaningful, honest, and unique.
        </p>
        <p>
          As I delved into my visual exploration of the lover archetype, I
          turned to AI image generator Midjourney as a tool to help me create
          compelling images that would capture the essence of this archetype.
          However, I soon discovered that the tool was heavily biased when it
          came to creating images of lovers and couples representing love.
        </p>
        <p>
          Many of the images generated by Midjourney portrayed stereotypical and
          outdated notions of love and romance. As you can see from Figure 10,
          many of the couple images showed heterosexual couples with traditional
          gender roles, such as a man carrying his partner in his arms or a
          woman gazing adoringly at her partner These portrayals reinforce the
          stereotype of men being physically powerful and competent, while women
          are presented as vulnerable objects in need of protection.
          Additionally, Midjourney's images consistently showed lovers as being
          physically attractive, fit, and adhering to societal standards of
          beauty.
        </p>

        <div class="grid">
          <div class="image-grid-1">
            <img
              src="images/figure10-one.png"
              alt="Image 101"
              width="auto"
              height="450px"
            />
            <img
              src="images/figure10-two.png"
              alt="Image 102"
              width="auto"
              height="450px"
            />
            <img
              src="images/figure10-three.png"
              alt="Image 103"
              width="auto"
              height="450px"
            />
          </div>

          <div class="image-grid-2">
            <img
              src="images/figure10-four.png"
              alt="Image 104"
              width="auto"
              height="450px"
            />
            <img
              src="images/figure10-five.png"
              alt="Image 105"
              width="auto"
              height="450px"
            />
            <img
              src="images/figure10-six.png"
              alt="Image 106"
              width="auto"
              height="450px"
            />
          </div>
          <div class="image-footnotes">
            Figure 10: Generated images with Midjourney AI tool with the prompt
            "the lovers", 2023
          </div>
        </div>
        <!--
        
        
        <br>
        <br>
        <br>
        <br>
-->
        <!--
     <div class="images">
       <img src="images/figure10-one.png" width="100%" height="auto">
         <div class="image-footnotes">Figure 10: Generated images with Midjourney AI tool with the prompt "the lovers", 2023</div>
       </div>
-->

        <p>
          This bias was frustrating to me, as it went against the values of
          honesty and authenticity that I believe all artists should strive for.
          I wanted to create images that represented love in all its complexity,
          with a diverse range of representations of gender, sexuality, and
          relationship dynamics.
        </p>

        <p>
          Upon further research, I discovered that Midjourney, like many AI
          tools, was biased because of the data it was trained on. Much of the
          data used to train the tool came from popular media, which often
          reinforces stereotypes and narrow representations of love and romance.
          This bias was perpetuated because of the way the AI algorithms work,
          which favor patterns and predictability over nuance and complexity. I
          realized that AI is not neutral or objective, but rather reflects the
          biases and values of the humans who create and train it. As it’s
          mentioned in the book "The Atlas of Anomalous AI", "AI is always
          political, cultural, and historical. It is never neutral, always
          situated within particular contexts and power relations."
        </p>

        <p>
          Nevertheless, there are contemporary artists who are able to create
          AI-generated artworks expressing the lover archetype in a new
          unexpected way. They often take on abstract and surreal qualities that
          convey the emotional and physical sensations associated with love and
          romance. These artworks challenge traditional notions of love and
          relationships, opening up new possibilities for artistic expression
          and exploration.
        </p>

        <p>
          One of the examples is “Alice and Bob” (2017) installation created by
          Anna Ridler and Daria Jelonek that consists of continuously evolving
          love letters generated and controlled by data produced by a four-qubit
          quantum computer. (11) Excerpts and titles of quantum science papers
          are processed and subsequently woven into a series of what appears to
          be handwritten, intimate letters shared between the fictitious
          characters of Alice and Bob, complicated by sporadic mentions of a
          third character, Eve.
        </p>

        <div class="image-5">
          <img src="images/figure11.png" width="100%" height="auto" />
          <div class="image-footnotes">
            Figure 11: Alice and Bob by Anna Ridler and Daria Jelonek, 2017
          </div>
        </div>

        <p>
          By re-contextualizing technical and algorithmic data within a love
          story, the installation of Anna and Daria reveals the unexpected
          connections and poetic intersections among science, literature, and
          art. With the three-act structure of the installatin, the artists
          depict the entangled storylines of Alice and Bob, similar to how
          photons in a quantum device become entangled. The language used by
          physicists to describe the quantum phenomenon of entanglements, such
          as fidelity, monogamy, and entangling, bears a striking resemblance to
          the language used in romance novels. Francis Ponge in his “The Augean
          Stables” describes how the same language is used by poets as it is by
          politicians and business: “because we have no other words at our
          disposal”. Anna with Daria certainly found that the same language
          which is used both to describe tightly-controlled experimental physics
          and the act of falling in and out of love.”
        </p>
      </div>

      <div class="conclusions">
        <a id="conclusions" class="chapter-title"><h2>Conclusions</h2></a>

        <p>
          Archetypes are a powerful tool in advertisement, art and design,
          providing a framework for understanding human behavior and motivation.
          However, as society continues to evolve and become more inclusive, it
          is important for artists to take a critical approach to the tools and
          techniques they use to create their work. While AI tools like
          Midjourney and Jung's archetypes can be helpful in generating ideas
          and sparking creativity, they should not be relied upon as a
          substitute for individual creativity and critical thinking.
        </p>

        <p>
          As a designer, it is important for me to be critical in using tools
          like AI and archetypes. It's necessary to be aware of the cultural
          stereotypes and biases that exist and to work towards subverting and
          challenging them in designs.
        </p>

        <p>
          Overall, my understanding of archetypes and visual exploration has
          helped me to become a more effective and thoughtful designer. By being
          critical in my use of tools like AI and archetypes, I can continue to
          create designs that are inclusive, diverse, and impactful.
        </p>
      </div>

      <div class="bibliography">
        <a id="bibliography" class="chapter-title">Bibliography</a>
        <div class="references">
          <br />
          Berger, J. (1972). Essay 3. In Ways of seeing. essay, BBC and Penguin.
          <br />
          Campbell, J., Moyers, B. D., and Flowers, B. S. (1991). The power of
          myth. Random House.
          <br />
          Freud, S.,and Brill, A. A. (2023). The interpretation of dreams.
          Legare Street Press, an imprint of Creative Media Partners.
          <br />
          Hartwell, M. P., Chen, J. C., and Spector, M. (2012). Archetypes in
          branding: A toolkit for creatives and strategists. How Books.
          <br />
          Jung, C. G. (1959). The archetypes and the collective unconscious.
          Routledge and Kegan Paul.
          <br />
          Jung, C. G.,and Campbell, J. (1985). The portable jung. Penguin Books.
          <br />
          Mark, M.,and Pearson, C. S. (2002). The Hero and the Outlaw:
          Harnessing the power of Archetypes to create a winning brand.
          McGraw-Hill.
          <br />
          Vickers, B., Allado-McDowell, K.,and Sherman, B. (2020). Atlas of
          anomalous ai. Ignota.
          <br />
        </div>
      </div>
    </div>

    <div class="bottom-panel" id="bottom-panel">
      <div class="popup-wrapper" id="popup-wrapper"></div>
    </div>

    <ol>
      <li id="fn:1">
        <p>
          Jung, C. G., and Campbell, J. (1985). The portable Jung. Penguin
          Books.
        </p>
      </li>

      <li id="fn:2">
        <p>
          Jung, C. G. (1959). The archetypes and the collective unconscious.
          Routledge and Kegan Paul.
        </p>
      </li>

      <li id="fn:3">
        <p>
          Campbell, J., Moyers, B. D., and Flowers, B. S. (1991). The power of
          myth. Random House.
        </p>
      </li>

      <li id="fn:4">
        <p>
          Freud, S., and Brill, A. A. (2023). The interpretation of dreams.
          Legare Street Press, an imprint of Creative Media Partners.
        </p>
      </li>
    </ol>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script src="index.js"></script>
    <script src="footnotes.js"></script>
    <script src="Gradient.js"></script>
    <script>
      /*
       *   Stripe WebGl Gradient Animation
       *   All Credits to Stripe.com
       *   ScrollObserver functionality to disable animation when not scrolled into view has been disabled and
       *   commented out for now.
       *   https://kevinhufnagl.com
       */

      //Converting colors to proper format
      function normalizeColor(hexCode) {
        return [
          ((hexCode >> 16) & 255) / 255,
          ((hexCode >> 8) & 255) / 255,
          (255 & hexCode) / 255,
        ];
      }
      ["SCREEN", "LINEAR_LIGHT"].reduce(
        (hexCode, t, n) =>
          Object.assign(hexCode, {
            [t]: n,
          }),
        {}
      );

      //Essential functionality of WebGl
      //t = width
      //n = height
      class MiniGl {
        constructor(canvas, width, height, debug = false) {
          const _miniGl = this,
            debug_output =
              -1 !==
              document.location.search.toLowerCase().indexOf("debug=webgl");
          (_miniGl.canvas = canvas),
            (_miniGl.gl = _miniGl.canvas.getContext("webgl", {
              antialias: true,
            })),
            (_miniGl.meshes = []);
          const context = _miniGl.gl;
          width && height && this.setSize(width, height),
            _miniGl.lastDebugMsg,
            (_miniGl.debug =
              debug && debug_output
                ? function (e) {
                    const t = new Date();
                    t - _miniGl.lastDebugMsg > 1e3 && console.log("---"),
                      console.log(
                        t.toLocaleTimeString() +
                          Array(Math.max(0, 32 - e.length)).join(" ") +
                          e +
                          ": ",
                        ...Array.from(arguments).slice(1)
                      ),
                      (_miniGl.lastDebugMsg = t);
                  }
                : () => {}),
            Object.defineProperties(_miniGl, {
              Material: {
                enumerable: false,
                value: class {
                  constructor(vertexShaders, fragments, uniforms = {}) {
                    const material = this;
                    function getShaderByType(type, source) {
                      const shader = context.createShader(type);
                      return (
                        context.shaderSource(shader, source),
                        context.compileShader(shader),
                        context.getShaderParameter(
                          shader,
                          context.COMPILE_STATUS
                        ) || console.error(context.getShaderInfoLog(shader)),
                        _miniGl.debug("Material.compileShaderSource", {
                          source: source,
                        }),
                        shader
                      );
                    }
                    function getUniformVariableDeclarations(uniforms, type) {
                      return Object.entries(uniforms)
                        .map(([uniform, value]) =>
                          value.getDeclaration(uniform, type)
                        )
                        .join("\n");
                    }
                    (material.uniforms = uniforms),
                      (material.uniformInstances = []);

                    const prefix =
                      "\n              precision highp float;\n            ";
                    (material.vertexSource = `\n              ${prefix}\n              attribute vec4 position;\n              attribute vec2 uv;\n              attribute vec2 uvNorm;\n              ${getUniformVariableDeclarations(
                      _miniGl.commonUniforms,
                      "vertex"
                    )}\n              ${getUniformVariableDeclarations(
                      uniforms,
                      "vertex"
                    )}\n              ${vertexShaders}\n            `),
                      (material.Source = `\n              ${prefix}\n              ${getUniformVariableDeclarations(
                        _miniGl.commonUniforms,
                        "fragment"
                      )}\n              ${getUniformVariableDeclarations(
                        uniforms,
                        "fragment"
                      )}\n              ${fragments}\n            `),
                      (material.vertexShader = getShaderByType(
                        context.VERTEX_SHADER,
                        material.vertexSource
                      )),
                      (material.fragmentShader = getShaderByType(
                        context.FRAGMENT_SHADER,
                        material.Source
                      )),
                      (material.program = context.createProgram()),
                      context.attachShader(
                        material.program,
                        material.vertexShader
                      ),
                      context.attachShader(
                        material.program,
                        material.fragmentShader
                      ),
                      context.linkProgram(material.program),
                      context.getProgramParameter(
                        material.program,
                        context.LINK_STATUS
                      ) ||
                        console.error(
                          context.getProgramInfoLog(material.program)
                        ),
                      context.useProgram(material.program),
                      material.attachUniforms(void 0, _miniGl.commonUniforms),
                      material.attachUniforms(void 0, material.uniforms);
                  }
                  //t = uniform
                  attachUniforms(name, uniforms) {
                    //n  = material
                    const material = this;
                    void 0 === name
                      ? Object.entries(uniforms).forEach(([name, uniform]) => {
                          material.attachUniforms(name, uniform);
                        })
                      : "array" == uniforms.type
                      ? uniforms.value.forEach((uniform, i) =>
                          material.attachUniforms(`${name}[${i}]`, uniform)
                        )
                      : "struct" == uniforms.type
                      ? Object.entries(uniforms.value).forEach(([uniform, i]) =>
                          material.attachUniforms(`${name}.${uniform}`, i)
                        )
                      : (_miniGl.debug("Material.attachUniforms", {
                          name: name,
                          uniform: uniforms,
                        }),
                        material.uniformInstances.push({
                          uniform: uniforms,
                          location: context.getUniformLocation(
                            material.program,
                            name
                          ),
                        }));
                  }
                },
              },
              Uniform: {
                enumerable: !1,
                value: class {
                  constructor(e) {
                    (this.type = "float"), Object.assign(this, e);
                    (this.typeFn =
                      {
                        float: "1f",
                        int: "1i",
                        vec2: "2fv",
                        vec3: "3fv",
                        vec4: "4fv",
                        mat4: "Matrix4fv",
                      }[this.type] || "1f"),
                      this.update();
                  }
                  update(value) {
                    void 0 !== this.value &&
                      context[`uniform${this.typeFn}`](
                        value,
                        0 === this.typeFn.indexOf("Matrix")
                          ? this.transpose
                          : this.value,
                        0 === this.typeFn.indexOf("Matrix") ? this.value : null
                      );
                  }
                  //e - name
                  //t - type
                  //n - length
                  getDeclaration(name, type, length) {
                    const uniform = this;
                    if (uniform.excludeFrom !== type) {
                      if ("array" === uniform.type)
                        return (
                          uniform.value[0].getDeclaration(
                            name,
                            type,
                            uniform.value.length
                          ) +
                          `\nconst int ${name}_length = ${uniform.value.length};`
                        );
                      if ("struct" === uniform.type) {
                        let name_no_prefix = name.replace("u_", "");
                        return (
                          (name_no_prefix =
                            name_no_prefix.charAt(0).toUpperCase() +
                            name_no_prefix.slice(1)),
                          `uniform struct ${name_no_prefix} 
                                {\n` +
                            Object.entries(uniform.value)
                              .map(([name, uniform]) =>
                                uniform
                                  .getDeclaration(name, type)
                                  .replace(/^uniform/, "")
                              )
                              .join("") +
                            `\n} ${name}${length > 0 ? `[${length}]` : ""};`
                        );
                      }
                      return `uniform ${uniform.type} ${name}${
                        length > 0 ? `[${length}]` : ""
                      };`;
                    }
                  }
                },
              },
              PlaneGeometry: {
                enumerable: !1,
                value: class {
                  constructor(width, height, n, i, orientation) {
                    context.createBuffer(),
                      (this.attributes = {
                        position: new _miniGl.Attribute({
                          target: context.ARRAY_BUFFER,
                          size: 3,
                        }),
                        uv: new _miniGl.Attribute({
                          target: context.ARRAY_BUFFER,
                          size: 2,
                        }),
                        uvNorm: new _miniGl.Attribute({
                          target: context.ARRAY_BUFFER,
                          size: 2,
                        }),
                        index: new _miniGl.Attribute({
                          target: context.ELEMENT_ARRAY_BUFFER,
                          size: 3,
                          type: context.UNSIGNED_SHORT,
                        }),
                      }),
                      this.setTopology(n, i),
                      this.setSize(width, height, orientation);
                  }
                  setTopology(e = 1, t = 1) {
                    const n = this;
                    (n.xSegCount = e),
                      (n.ySegCount = t),
                      (n.vertexCount = (n.xSegCount + 1) * (n.ySegCount + 1)),
                      (n.quadCount = n.xSegCount * n.ySegCount * 2),
                      (n.attributes.uv.values = new Float32Array(
                        2 * n.vertexCount
                      )),
                      (n.attributes.uvNorm.values = new Float32Array(
                        2 * n.vertexCount
                      )),
                      (n.attributes.index.values = new Uint16Array(
                        3 * n.quadCount
                      ));
                    for (let e = 0; e <= n.ySegCount; e++)
                      for (let t = 0; t <= n.xSegCount; t++) {
                        const i = e * (n.xSegCount + 1) + t;
                        if (
                          ((n.attributes.uv.values[2 * i] = t / n.xSegCount),
                          (n.attributes.uv.values[2 * i + 1] =
                            1 - e / n.ySegCount),
                          (n.attributes.uvNorm.values[2 * i] =
                            (t / n.xSegCount) * 2 - 1),
                          (n.attributes.uvNorm.values[2 * i + 1] =
                            1 - (e / n.ySegCount) * 2),
                          t < n.xSegCount && e < n.ySegCount)
                        ) {
                          const s = e * n.xSegCount + t;
                          (n.attributes.index.values[6 * s] = i),
                            (n.attributes.index.values[6 * s + 1] =
                              i + 1 + n.xSegCount),
                            (n.attributes.index.values[6 * s + 2] = i + 1),
                            (n.attributes.index.values[6 * s + 3] = i + 1),
                            (n.attributes.index.values[6 * s + 4] =
                              i + 1 + n.xSegCount),
                            (n.attributes.index.values[6 * s + 5] =
                              i + 2 + n.xSegCount);
                        }
                      }
                    n.attributes.uv.update(),
                      n.attributes.uvNorm.update(),
                      n.attributes.index.update(),
                      _miniGl.debug("Geometry.setTopology", {
                        uv: n.attributes.uv,
                        uvNorm: n.attributes.uvNorm,
                        index: n.attributes.index,
                      });
                  }
                  setSize(width = 1, height = 1, orientation = "xz") {
                    const geometry = this;
                    (geometry.width = width),
                      (geometry.height = height),
                      (geometry.orientation = orientation),
                      (geometry.attributes.position.values &&
                        geometry.attributes.position.values.length ===
                          3 * geometry.vertexCount) ||
                        (geometry.attributes.position.values = new Float32Array(
                          3 * geometry.vertexCount
                        ));
                    const o = width / -2,
                      r = height / -2,
                      segment_width = width / geometry.xSegCount,
                      segment_height = height / geometry.ySegCount;
                    for (
                      let yIndex = 0;
                      yIndex <= geometry.ySegCount;
                      yIndex++
                    ) {
                      const t = r + yIndex * segment_height;
                      for (
                        let xIndex = 0;
                        xIndex <= geometry.xSegCount;
                        xIndex++
                      ) {
                        const r = o + xIndex * segment_width,
                          l = yIndex * (geometry.xSegCount + 1) + xIndex;
                        (geometry.attributes.position.values[
                          3 * l + "xyz".indexOf(orientation[0])
                        ] = r),
                          (geometry.attributes.position.values[
                            3 * l + "xyz".indexOf(orientation[1])
                          ] = -t);
                      }
                    }
                    geometry.attributes.position.update(),
                      _miniGl.debug("Geometry.setSize", {
                        position: geometry.attributes.position,
                      });
                  }
                },
              },
              Mesh: {
                enumerable: !1,
                value: class {
                  constructor(geometry, material) {
                    const mesh = this;
                    (mesh.geometry = geometry),
                      (mesh.material = material),
                      (mesh.wireframe = !1),
                      (mesh.attributeInstances = []),
                      Object.entries(mesh.geometry.attributes).forEach(
                        ([e, attribute]) => {
                          mesh.attributeInstances.push({
                            attribute: attribute,
                            location: attribute.attach(
                              e,
                              mesh.material.program
                            ),
                          });
                        }
                      ),
                      _miniGl.meshes.push(mesh),
                      _miniGl.debug("Mesh.constructor", {
                        mesh: mesh,
                      });
                  }
                  draw() {
                    context.useProgram(this.material.program),
                      this.material.uniformInstances.forEach(
                        ({ uniform: e, location: t }) => e.update(t)
                      ),
                      this.attributeInstances.forEach(
                        ({ attribute: e, location: t }) => e.use(t)
                      ),
                      context.drawElements(
                        this.wireframe ? context.LINES : context.TRIANGLES,
                        this.geometry.attributes.index.values.length,
                        context.UNSIGNED_SHORT,
                        0
                      );
                  }
                  remove() {
                    _miniGl.meshes = _miniGl.meshes.filter((e) => e != this);
                  }
                },
              },
              Attribute: {
                enumerable: !1,
                value: class {
                  constructor(e) {
                    (this.type = context.FLOAT),
                      (this.normalized = !1),
                      (this.buffer = context.createBuffer()),
                      Object.assign(this, e),
                      this.update();
                  }
                  update() {
                    void 0 !== this.values &&
                      (context.bindBuffer(this.target, this.buffer),
                      context.bufferData(
                        this.target,
                        this.values,
                        context.STATIC_DRAW
                      ));
                  }
                  attach(e, t) {
                    const n = context.getAttribLocation(t, e);
                    return (
                      this.target === context.ARRAY_BUFFER &&
                        (context.enableVertexAttribArray(n),
                        context.vertexAttribPointer(
                          n,
                          this.size,
                          this.type,
                          this.normalized,
                          0,
                          0
                        )),
                      n
                    );
                  }
                  use(e) {
                    context.bindBuffer(this.target, this.buffer),
                      this.target === context.ARRAY_BUFFER &&
                        (context.enableVertexAttribArray(e),
                        context.vertexAttribPointer(
                          e,
                          this.size,
                          this.type,
                          this.normalized,
                          0,
                          0
                        ));
                  }
                },
              },
            });
          const a = [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1];
          _miniGl.commonUniforms = {
            projectionMatrix: new _miniGl.Uniform({
              type: "mat4",
              value: a,
            }),
            modelViewMatrix: new _miniGl.Uniform({
              type: "mat4",
              value: a,
            }),
            resolution: new _miniGl.Uniform({
              type: "vec2",
              value: [1, 1],
            }),
            aspectRatio: new _miniGl.Uniform({
              type: "float",
              value: 1,
            }),
          };
        }
        setSize(e = 640, t = 480) {
          (this.width = e),
            (this.height = t),
            (this.canvas.width = e),
            (this.canvas.height = t),
            this.gl.viewport(0, 0, e, t),
            (this.commonUniforms.resolution.value = [e, t]),
            (this.commonUniforms.aspectRatio.value = e / t),
            this.debug("MiniGL.setSize", {
              width: e,
              height: t,
            });
        }
        //left, right, top, bottom, near, far
        setOrthographicCamera(e = 0, t = 0, n = 0, i = -2e3, s = 2e3) {
          (this.commonUniforms.projectionMatrix.value = [
            2 / this.width,
            0,
            0,
            0,
            0,
            2 / this.height,
            0,
            0,
            0,
            0,
            2 / (i - s),
            0,
            e,
            t,
            n,
            1,
          ]),
            this.debug(
              "setOrthographicCamera",
              this.commonUniforms.projectionMatrix.value
            );
        }
        render() {
          this.gl.clearColor(0, 0, 0, 0),
            this.gl.clearDepth(1),
            this.meshes.forEach((e) => e.draw());
        }
      }

      //Sets initial properties
      function e(object, propertyName, val) {
        return (
          propertyName in object
            ? Object.defineProperty(object, propertyName, {
                value: val,
                enumerable: !0,
                configurable: !0,
                writable: !0,
              })
            : (object[propertyName] = val),
          object
        );
      }

      //Gradient object
      class Gradient {
        constructor(...t) {
          e(this, "el", void 0),
            e(this, "cssVarRetries", 0),
            e(this, "maxCssVarRetries", 200),
            e(this, "angle", 0),
            e(this, "isLoadedClass", !1),
            e(this, "isScrolling", !1),
            /*e(this, "isStatic", o.disableAmbientAnimations()),*/ e(
              this,
              "scrollingTimeout",
              void 0
            ),
            e(this, "scrollingRefreshDelay", 200),
            e(this, "isIntersecting", !1),
            e(this, "shaderFiles", void 0),
            e(this, "vertexShader", void 0),
            e(this, "sectionColors", void 0),
            e(this, "computedCanvasStyle", void 0),
            e(this, "conf", void 0),
            e(this, "uniforms", void 0),
            e(this, "t", 1253106),
            e(this, "last", 0),
            e(this, "width", void 0),
            e(this, "minWidth", 1111),
            e(this, "height", 600),
            e(this, "xSegCount", void 0),
            e(this, "ySegCount", void 0),
            e(this, "mesh", void 0),
            e(this, "material", void 0),
            e(this, "geometry", void 0),
            e(this, "minigl", void 0),
            e(this, "scrollObserver", void 0),
            e(this, "amp", 320),
            e(this, "seed", 5),
            e(this, "freqX", 14e-5),
            e(this, "freqY", 29e-5),
            e(this, "freqDelta", 1e-5),
            e(this, "activeColors", [1, 1, 1, 1]),
            e(this, "isMetaKey", !1),
            e(this, "isGradientLegendVisible", !1),
            e(this, "isMouseDown", !1),
            e(this, "handleScroll", () => {
              clearTimeout(this.scrollingTimeout),
                (this.scrollingTimeout = setTimeout(
                  this.handleScrollEnd,
                  this.scrollingRefreshDelay
                )),
                this.isGradientLegendVisible && this.hideGradientLegend(),
                this.conf.playing && ((this.isScrolling = !0), this.pause());
            }),
            e(this, "handleScrollEnd", () => {
              (this.isScrolling = !1), this.isIntersecting && this.play();
            }),
            e(this, "resize", () => {
              (this.width = window.innerWidth),
                this.minigl.setSize(this.width, this.height),
                this.minigl.setOrthographicCamera(),
                (this.xSegCount = Math.ceil(this.width * this.conf.density[0])),
                (this.ySegCount = Math.ceil(
                  this.height * this.conf.density[1]
                )),
                this.mesh.geometry.setTopology(this.xSegCount, this.ySegCount),
                this.mesh.geometry.setSize(this.width, this.height),
                (this.mesh.material.uniforms.u_shadow_power.value =
                  this.width < 600 ? 5 : 6);
            }),
            e(this, "handleMouseDown", (e) => {
              this.isGradientLegendVisible &&
                ((this.isMetaKey = e.metaKey),
                (this.isMouseDown = !0),
                !1 === this.conf.playing &&
                  requestAnimationFrame(this.animate));
            }),
            e(this, "handleMouseUp", () => {
              this.isMouseDown = !1;
            }),
            e(this, "animate", (e) => {
              if (!this.shouldSkipFrame(e) || this.isMouseDown) {
                if (
                  ((this.t += Math.min(e - this.last, 1e3 / 15)),
                  (this.last = e),
                  this.isMouseDown)
                ) {
                  let e = 160;
                  this.isMetaKey && (e = -160), (this.t += e);
                }
                (this.mesh.material.uniforms.u_time.value = this.t),
                  this.minigl.render();
              }
              if (0 !== this.last && this.isStatic)
                return this.minigl.render(), void this.disconnect();
              /*this.isIntersecting && */ (this.conf.playing ||
                this.isMouseDown) &&
                requestAnimationFrame(this.animate);
            }),
            e(this, "addIsLoadedClass", () => {
              /*this.isIntersecting && */ !this.isLoadedClass &&
                ((this.isLoadedClass = !0),
                this.el.classList.add("isLoaded"),
                setTimeout(() => {
                  this.el.parentElement.classList.add("isLoaded");
                }, 3e3));
            }),
            e(this, "pause", () => {
              this.conf.playing = false;
            }),
            e(this, "play", () => {
              requestAnimationFrame(this.animate), (this.conf.playing = true);
            }),
            e(this, "initGradient", (selector) => {
              this.el = document.querySelector(selector);
              this.connect();
              return this;
            });
        }
        async connect() {
          (this.shaderFiles = {
            vertex:
              "varying vec3 v_color;\n\nvoid main() {\n  float time = u_time * u_global.noiseSpeed;\n\n  vec2 noiseCoord = resolution * uvNorm * u_global.noiseFreq;\n\n  vec2 st = 1. - uvNorm.xy;\n\n  //\n  // Tilting the plane\n  //\n\n  // Front-to-back tilt\n  float tilt = resolution.y / 2.0 * uvNorm.y;\n\n  // Left-to-right angle\n  float incline = resolution.x * uvNorm.x / 2.0 * u_vertDeform.incline;\n\n  // Up-down shift to offset incline\n  float offset = resolution.x / 2.0 * u_vertDeform.incline * mix(u_vertDeform.offsetBottom, u_vertDeform.offsetTop, uv.y);\n\n  //\n  // Vertex noise\n  //\n\n  float noise = snoise(vec3(\n    noiseCoord.x * u_vertDeform.noiseFreq.x + time * u_vertDeform.noiseFlow,\n    noiseCoord.y * u_vertDeform.noiseFreq.y,\n    time * u_vertDeform.noiseSpeed + u_vertDeform.noiseSeed\n  )) * u_vertDeform.noiseAmp;\n\n  // Fade noise to zero at edges\n  noise *= 1.0 - pow(abs(uvNorm.y), 2.0);\n\n  // Clamp to 0\n  noise = max(0.0, noise);\n\n  vec3 pos = vec3(\n    position.x,\n    position.y + tilt + incline + noise - offset,\n    position.z\n  );\n\n  //\n  // Vertex color, to be passed to fragment shader\n  //\n\n  if (u_active_colors[0] == 1.) {\n    v_color = u_baseColor;\n  }\n\n  for (int i = 0; i < u_waveLayers_length; i++) {\n    if (u_active_colors[i + 1] == 1.) {\n      WaveLayers layer = u_waveLayers[i];\n\n      float noise = smoothstep(\n        layer.noiseFloor,\n        layer.noiseCeil,\n        snoise(vec3(\n          noiseCoord.x * layer.noiseFreq.x + time * layer.noiseFlow,\n          noiseCoord.y * layer.noiseFreq.y,\n          time * layer.noiseSpeed + layer.noiseSeed\n        )) / 2.0 + 0.5\n      );\n\n      v_color = blendNormal(v_color, layer.color, pow(noise, 4.));\n    }\n  }\n\n  //\n  // Finish\n  //\n\n  gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);\n}",
            noise:
              "//\n// Description : Array and textureless GLSL 2D/3D/4D simplex\n//               noise functions.\n//      Author : Ian McEwan, Ashima Arts.\n//  Maintainer : stegu\n//     Lastmod : 20110822 (ijm)\n//     License : Copyright (C) 2011 Ashima Arts. All rights reserved.\n//               Distributed under the MIT License. See LICENSE file.\n//               https://github.com/ashima/webgl-noise\n//               https://github.com/stegu/webgl-noise\n//\n\nvec3 mod289(vec3 x) {\n  return x - floor(x * (1.0 / 289.0)) * 289.0;\n}\n\nvec4 mod289(vec4 x) {\n  return x - floor(x * (1.0 / 289.0)) * 289.0;\n}\n\nvec4 permute(vec4 x) {\n    return mod289(((x*34.0)+1.0)*x);\n}\n\nvec4 taylorInvSqrt(vec4 r)\n{\n  return 1.79284291400159 - 0.85373472095314 * r;\n}\n\nfloat snoise(vec3 v)\n{\n  const vec2  C = vec2(1.0/6.0, 1.0/3.0) ;\n  const vec4  D = vec4(0.0, 0.5, 1.0, 2.0);\n\n// First corner\n  vec3 i  = floor(v + dot(v, C.yyy) );\n  vec3 x0 =   v - i + dot(i, C.xxx) ;\n\n// Other corners\n  vec3 g = step(x0.yzx, x0.xyz);\n  vec3 l = 1.0 - g;\n  vec3 i1 = min( g.xyz, l.zxy );\n  vec3 i2 = max( g.xyz, l.zxy );\n\n  //   x0 = x0 - 0.0 + 0.0 * C.xxx;\n  //   x1 = x0 - i1  + 1.0 * C.xxx;\n  //   x2 = x0 - i2  + 2.0 * C.xxx;\n  //   x3 = x0 - 1.0 + 3.0 * C.xxx;\n  vec3 x1 = x0 - i1 + C.xxx;\n  vec3 x2 = x0 - i2 + C.yyy; // 2.0*C.x = 1/3 = C.y\n  vec3 x3 = x0 - D.yyy;      // -1.0+3.0*C.x = -0.5 = -D.y\n\n// Permutations\n  i = mod289(i);\n  vec4 p = permute( permute( permute(\n            i.z + vec4(0.0, i1.z, i2.z, 1.0 ))\n          + i.y + vec4(0.0, i1.y, i2.y, 1.0 ))\n          + i.x + vec4(0.0, i1.x, i2.x, 1.0 ));\n\n// Gradients: 7x7 points over a square, mapped onto an octahedron.\n// The ring size 17*17 = 289 is close to a multiple of 49 (49*6 = 294)\n  float n_ = 0.142857142857; // 1.0/7.0\n  vec3  ns = n_ * D.wyz - D.xzx;\n\n  vec4 j = p - 49.0 * floor(p * ns.z * ns.z);  //  mod(p,7*7)\n\n  vec4 x_ = floor(j * ns.z);\n  vec4 y_ = floor(j - 7.0 * x_ );    // mod(j,N)\n\n  vec4 x = x_ *ns.x + ns.yyyy;\n  vec4 y = y_ *ns.x + ns.yyyy;\n  vec4 h = 1.0 - abs(x) - abs(y);\n\n  vec4 b0 = vec4( x.xy, y.xy );\n  vec4 b1 = vec4( x.zw, y.zw );\n\n  //vec4 s0 = vec4(lessThan(b0,0.0))*2.0 - 1.0;\n  //vec4 s1 = vec4(lessThan(b1,0.0))*2.0 - 1.0;\n  vec4 s0 = floor(b0)*2.0 + 1.0;\n  vec4 s1 = floor(b1)*2.0 + 1.0;\n  vec4 sh = -step(h, vec4(0.0));\n\n  vec4 a0 = b0.xzyw + s0.xzyw*sh.xxyy ;\n  vec4 a1 = b1.xzyw + s1.xzyw*sh.zzww ;\n\n  vec3 p0 = vec3(a0.xy,h.x);\n  vec3 p1 = vec3(a0.zw,h.y);\n  vec3 p2 = vec3(a1.xy,h.z);\n  vec3 p3 = vec3(a1.zw,h.w);\n\n//Normalise gradients\n  vec4 norm = taylorInvSqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));\n  p0 *= norm.x;\n  p1 *= norm.y;\n  p2 *= norm.z;\n  p3 *= norm.w;\n\n// Mix final noise value\n  vec4 m = max(0.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.0);\n  m = m * m;\n  return 42.0 * dot( m*m, vec4( dot(p0,x0), dot(p1,x1),\n                                dot(p2,x2), dot(p3,x3) ) );\n}",
            blend:
              "//\n// https://github.com/jamieowen/glsl-blend\n//\n\n// Normal\n\nvec3 blendNormal(vec3 base, vec3 blend) {\n\treturn blend;\n}\n\nvec3 blendNormal(vec3 base, vec3 blend, float opacity) {\n\treturn (blendNormal(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Screen\n\nfloat blendScreen(float base, float blend) {\n\treturn 1.0-((1.0-base)*(1.0-blend));\n}\n\nvec3 blendScreen(vec3 base, vec3 blend) {\n\treturn vec3(blendScreen(base.r,blend.r),blendScreen(base.g,blend.g),blendScreen(base.b,blend.b));\n}\n\nvec3 blendScreen(vec3 base, vec3 blend, float opacity) {\n\treturn (blendScreen(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Multiply\n\nvec3 blendMultiply(vec3 base, vec3 blend) {\n\treturn base*blend;\n}\n\nvec3 blendMultiply(vec3 base, vec3 blend, float opacity) {\n\treturn (blendMultiply(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Overlay\n\nfloat blendOverlay(float base, float blend) {\n\treturn base<0.5?(2.0*base*blend):(1.0-2.0*(1.0-base)*(1.0-blend));\n}\n\nvec3 blendOverlay(vec3 base, vec3 blend) {\n\treturn vec3(blendOverlay(base.r,blend.r),blendOverlay(base.g,blend.g),blendOverlay(base.b,blend.b));\n}\n\nvec3 blendOverlay(vec3 base, vec3 blend, float opacity) {\n\treturn (blendOverlay(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Hard light\n\nvec3 blendHardLight(vec3 base, vec3 blend) {\n\treturn blendOverlay(blend,base);\n}\n\nvec3 blendHardLight(vec3 base, vec3 blend, float opacity) {\n\treturn (blendHardLight(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Soft light\n\nfloat blendSoftLight(float base, float blend) {\n\treturn (blend<0.5)?(2.0*base*blend+base*base*(1.0-2.0*blend)):(sqrt(base)*(2.0*blend-1.0)+2.0*base*(1.0-blend));\n}\n\nvec3 blendSoftLight(vec3 base, vec3 blend) {\n\treturn vec3(blendSoftLight(base.r,blend.r),blendSoftLight(base.g,blend.g),blendSoftLight(base.b,blend.b));\n}\n\nvec3 blendSoftLight(vec3 base, vec3 blend, float opacity) {\n\treturn (blendSoftLight(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Color dodge\n\nfloat blendColorDodge(float base, float blend) {\n\treturn (blend==1.0)?blend:min(base/(1.0-blend),1.0);\n}\n\nvec3 blendColorDodge(vec3 base, vec3 blend) {\n\treturn vec3(blendColorDodge(base.r,blend.r),blendColorDodge(base.g,blend.g),blendColorDodge(base.b,blend.b));\n}\n\nvec3 blendColorDodge(vec3 base, vec3 blend, float opacity) {\n\treturn (blendColorDodge(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Color burn\n\nfloat blendColorBurn(float base, float blend) {\n\treturn (blend==0.0)?blend:max((1.0-((1.0-base)/blend)),0.0);\n}\n\nvec3 blendColorBurn(vec3 base, vec3 blend) {\n\treturn vec3(blendColorBurn(base.r,blend.r),blendColorBurn(base.g,blend.g),blendColorBurn(base.b,blend.b));\n}\n\nvec3 blendColorBurn(vec3 base, vec3 blend, float opacity) {\n\treturn (blendColorBurn(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Vivid Light\n\nfloat blendVividLight(float base, float blend) {\n\treturn (blend<0.5)?blendColorBurn(base,(2.0*blend)):blendColorDodge(base,(2.0*(blend-0.5)));\n}\n\nvec3 blendVividLight(vec3 base, vec3 blend) {\n\treturn vec3(blendVividLight(base.r,blend.r),blendVividLight(base.g,blend.g),blendVividLight(base.b,blend.b));\n}\n\nvec3 blendVividLight(vec3 base, vec3 blend, float opacity) {\n\treturn (blendVividLight(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Lighten\n\nfloat blendLighten(float base, float blend) {\n\treturn max(blend,base);\n}\n\nvec3 blendLighten(vec3 base, vec3 blend) {\n\treturn vec3(blendLighten(base.r,blend.r),blendLighten(base.g,blend.g),blendLighten(base.b,blend.b));\n}\n\nvec3 blendLighten(vec3 base, vec3 blend, float opacity) {\n\treturn (blendLighten(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Linear burn\n\nfloat blendLinearBurn(float base, float blend) {\n\t// Note : Same implementation as BlendSubtractf\n\treturn max(base+blend-1.0,0.0);\n}\n\nvec3 blendLinearBurn(vec3 base, vec3 blend) {\n\t// Note : Same implementation as BlendSubtract\n\treturn max(base+blend-vec3(1.0),vec3(0.0));\n}\n\nvec3 blendLinearBurn(vec3 base, vec3 blend, float opacity) {\n\treturn (blendLinearBurn(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Linear dodge\n\nfloat blendLinearDodge(float base, float blend) {\n\t// Note : Same implementation as BlendAddf\n\treturn min(base+blend,1.0);\n}\n\nvec3 blendLinearDodge(vec3 base, vec3 blend) {\n\t// Note : Same implementation as BlendAdd\n\treturn min(base+blend,vec3(1.0));\n}\n\nvec3 blendLinearDodge(vec3 base, vec3 blend, float opacity) {\n\treturn (blendLinearDodge(base, blend) * opacity + base * (1.0 - opacity));\n}\n\n// Linear light\n\nfloat blendLinearLight(float base, float blend) {\n\treturn blend<0.5?blendLinearBurn(base,(2.0*blend)):blendLinearDodge(base,(2.0*(blend-0.5)));\n}\n\nvec3 blendLinearLight(vec3 base, vec3 blend) {\n\treturn vec3(blendLinearLight(base.r,blend.r),blendLinearLight(base.g,blend.g),blendLinearLight(base.b,blend.b));\n}\n\nvec3 blendLinearLight(vec3 base, vec3 blend, float opacity) {\n\treturn (blendLinearLight(base, blend) * opacity + base * (1.0 - opacity));\n}",
            fragment:
              "varying vec3 v_color;\n\nvoid main() {\n  vec3 color = v_color;\n  if (u_darken_top == 1.0) {\n    vec2 st = gl_FragCoord.xy/resolution.xy;\n    color.g -= pow(st.y + sin(-12.0) * st.x, u_shadow_power) * 0.4;\n  }\n  gl_FragColor = vec4(color, 1.0);\n}",
          }),
            (this.conf = {
              presetName: "",
              wireframe: false,
              density: [0.06, 0.16],
              zoom: 1,
              rotation: 0,
              playing: true,
            }),
            document.querySelectorAll("canvas").length < 1
              ? console.log("DID NOT LOAD HERO STRIPE CANVAS")
              : ((this.minigl = new MiniGl(this.el, null, null, !0)),
                requestAnimationFrame(() => {
                  this.el &&
                    ((this.computedCanvasStyle = getComputedStyle(this.el)),
                    this.waitForCssVars());
                }));
          /*
        this.scrollObserver = await s.create(.1, !1),
        this.scrollObserver.observe(this.el),
        this.scrollObserver.onSeparate(() => {
            window.removeEventListener("scroll", this.handleScroll), window.removeEventListener("mousedown", this.handleMouseDown), window.removeEventListener("mouseup", this.handleMouseUp), window.removeEventListener("keydown", this.handleKeyDown), this.isIntersecting = !1, this.conf.playing && this.pause()
        }), 
        this.scrollObserver.onIntersect(() => {
            window.addEventListener("scroll", this.handleScroll), window.addEventListener("mousedown", this.handleMouseDown), window.addEventListener("mouseup", this.handleMouseUp), window.addEventListener("keydown", this.handleKeyDown), this.isIntersecting = !0, this.addIsLoadedClass(), this.play()
        })*/
        }
        disconnect() {
          this.scrollObserver &&
            (window.removeEventListener("scroll", this.handleScroll),
            window.removeEventListener("mousedown", this.handleMouseDown),
            window.removeEventListener("mouseup", this.handleMouseUp),
            window.removeEventListener("keydown", this.handleKeyDown),
            this.scrollObserver.disconnect()),
            window.removeEventListener("resize", this.resize);
        }
        initMaterial() {
          this.uniforms = {
            u_time: new this.minigl.Uniform({
              value: 0,
            }),
            u_shadow_power: new this.minigl.Uniform({
              value: 5,
            }),
            u_darken_top: new this.minigl.Uniform({
              value: "" === this.el.dataset.jsDarkenTop ? 1 : 0,
            }),
            u_active_colors: new this.minigl.Uniform({
              value: this.activeColors,
              type: "vec4",
            }),
            u_global: new this.minigl.Uniform({
              value: {
                noiseFreq: new this.minigl.Uniform({
                  value: [this.freqX, this.freqY],
                  type: "vec2",
                }),
                noiseSpeed: new this.minigl.Uniform({
                  value: 5e-6,
                }),
              },
              type: "struct",
            }),
            u_vertDeform: new this.minigl.Uniform({
              value: {
                incline: new this.minigl.Uniform({
                  value: Math.sin(this.angle) / Math.cos(this.angle),
                }),
                offsetTop: new this.minigl.Uniform({
                  value: -0.5,
                }),
                offsetBottom: new this.minigl.Uniform({
                  value: -0.5,
                }),
                noiseFreq: new this.minigl.Uniform({
                  value: [3, 4],
                  type: "vec2",
                }),
                noiseAmp: new this.minigl.Uniform({
                  value: this.amp,
                }),
                noiseSpeed: new this.minigl.Uniform({
                  value: 10,
                }),
                noiseFlow: new this.minigl.Uniform({
                  value: 3,
                }),
                noiseSeed: new this.minigl.Uniform({
                  value: this.seed,
                }),
              },
              type: "struct",
              excludeFrom: "fragment",
            }),
            u_baseColor: new this.minigl.Uniform({
              value: this.sectionColors[0],
              type: "vec3",
              excludeFrom: "fragment",
            }),
            u_waveLayers: new this.minigl.Uniform({
              value: [],
              excludeFrom: "fragment",
              type: "array",
            }),
          };
          for (let e = 1; e < this.sectionColors.length; e += 1)
            this.uniforms.u_waveLayers.value.push(
              new this.minigl.Uniform({
                value: {
                  color: new this.minigl.Uniform({
                    value: this.sectionColors[e],
                    type: "vec3",
                  }),
                  noiseFreq: new this.minigl.Uniform({
                    value: [
                      2 + e / this.sectionColors.length,
                      3 + e / this.sectionColors.length,
                    ],
                    type: "vec2",
                  }),
                  noiseSpeed: new this.minigl.Uniform({
                    value: 11 + 0.3 * e,
                  }),
                  noiseFlow: new this.minigl.Uniform({
                    value: 6.5 + 0.3 * e,
                  }),
                  noiseSeed: new this.minigl.Uniform({
                    value: this.seed + 10 * e,
                  }),
                  noiseFloor: new this.minigl.Uniform({
                    value: 0.1,
                  }),
                  noiseCeil: new this.minigl.Uniform({
                    value: 0.63 + 0.07 * e,
                  }),
                },
                type: "struct",
              })
            );
          return (
            (this.vertexShader = [
              this.shaderFiles.noise,
              this.shaderFiles.blend,
              this.shaderFiles.vertex,
            ].join("\n\n")),
            new this.minigl.Material(
              this.vertexShader,
              this.shaderFiles.fragment,
              this.uniforms
            )
          );
        }
        initMesh() {
          (this.material = this.initMaterial()),
            (this.geometry = new this.minigl.PlaneGeometry()),
            (this.mesh = new this.minigl.Mesh(this.geometry, this.material));
        }
        shouldSkipFrame(e) {
          return (
            !!window.document.hidden ||
            !this.conf.playing ||
            parseInt(e, 10) % 2 == 0 ||
            void 0
          );
        }
        updateFrequency(e) {
          (this.freqX += e), (this.freqY += e);
        }
        toggleColor(index) {
          this.activeColors[index] = 0 === this.activeColors[index] ? 1 : 0;
        }
        showGradientLegend() {
          this.width > this.minWidth &&
            ((this.isGradientLegendVisible = !0),
            document.body.classList.add("isGradientLegendVisible"));
        }
        hideGradientLegend() {
          (this.isGradientLegendVisible = !1),
            document.body.classList.remove("isGradientLegendVisible");
        }
        init() {
          this.initGradientColors(),
            this.initMesh(),
            this.resize(),
            requestAnimationFrame(this.animate),
            window.addEventListener("resize", this.resize);
        }
        /*
         * Waiting for the css variables to become available, usually on page load before we can continue.
         * Using default colors assigned below if no variables have been found after maxCssVarRetries
         */
        waitForCssVars() {
          if (
            this.computedCanvasStyle &&
            -1 !==
              this.computedCanvasStyle
                .getPropertyValue("--gradient-color-1")
                .indexOf("#")
          )
            this.init(), this.addIsLoadedClass();
          else {
            if (
              ((this.cssVarRetries += 1),
              this.cssVarRetries > this.maxCssVarRetries)
            ) {
              return (
                (this.sectionColors = [
                  16711680, 16711680, 16711935, 65280, 255,
                ]),
                void this.init()
              );
            }
            requestAnimationFrame(() => this.waitForCssVars());
          }
        }
        /*
         * Initializes the four section colors by retrieving them from css variables.
         */
        initGradientColors() {
          this.sectionColors = [
            "--gradient-color-1",
            "--gradient-color-2",
            "--gradient-color-3",
            "--gradient-color-4",
          ]
            .map((cssPropertyName) => {
              let hex = this.computedCanvasStyle
                .getPropertyValue(cssPropertyName)
                .trim();
              //Check if shorthand hex value was used and double the length so the conversion in normalizeColor will work.
              if (4 === hex.length) {
                const hexTemp = hex
                  .substr(1)
                  .split("")
                  .map((hexTemp) => hexTemp + hexTemp)
                  .join("");
                hex = `#${hexTemp}`;
              }
              return hex && `0x${hex.substr(1)}`;
            })
            .filter(Boolean)
            .map(normalizeColor);
        }
      }

      /*
       *Finally initializing the Gradient class, assigning a canvas to it and calling Gradient.connect() which initializes everything,
       * Use Gradient.pause() and Gradient.play() for controls.
       *
       * Here are some default property values you can change anytime:
       * Amplitude:    Gradient.amp = 0
       * Colors:       Gradient.sectionColors (if you change colors, use normalizeColor(#hexValue)) before you assign it.
       *
       *
       * Useful functions
       * Gradient.toggleColor(index)
       * Gradient.updateFrequency(freq)
       */

      // Create your instance
      const gradient = new Gradient();

      // Call `initGradient` with the selector to your canvas
      gradient.initGradient("#gradient-canvas");
    </script>
  </body>
</html>